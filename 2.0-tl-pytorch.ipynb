{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please Note**: We updated the requirements.txt\n",
    "\n",
    "Please install the new requirements before editing this exercise."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from vll.utils.download import download_mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "from models.mnist.simple_cnn import Net"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "(2 points)\n",
    "\n",
    "In this task, you will learn some basic tensor operations using the PyTorch library.\n",
    "\n",
    "Reference for torch: https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
      "        14., 15., 16., 17., 18., 19.])\n",
      "tensor([ 0.0000,  0.9809,  1.4071,  1.2338,  0.5557,  3.3603,  2.6949,  5.4415,\n",
      "         2.1138,  7.1021,  5.6113,  9.5517, 11.7541,  2.3736,  0.6000,  1.3571,\n",
      "         0.9439, 10.6800, 12.5842, 12.7149])\n",
      "tensor([-1.0000, -0.0191,  0.4071,  0.2338, -0.4443,  2.3603,  1.6949,  4.4415,\n",
      "         1.1138,  6.1021,  4.6113,  8.5517, 10.7541,  1.3736, -0.4000,  0.3571,\n",
      "        -0.0561,  9.6800, 11.5842, 11.7149])\n",
      "tensor(2.3603)\n",
      "tensor([-0., -0., 0., 0., -0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -0., 0., -0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Create a numpy array that looks like this: [0, 1, 2, ..., 19]\n",
    "arr = np.arange(20)\n",
    "print(arr)\n",
    "\n",
    "# Convert the numpy array to a torch tensor\n",
    "tensor = torch.tensor(arr, dtype=torch.float32)  # Specify dtype as float to not face compatibility issues later\n",
    "print(tensor)\n",
    "\n",
    "# Create a tensor that contains random numbers.\n",
    "# It should have the same size like the numpy array.\n",
    "# Multiply it with the previous tensor.\n",
    "rand_tensor = torch.rand_like(tensor)\n",
    "tensor = tensor * rand_tensor\n",
    "print(tensor)\n",
    "\n",
    "# Create a tensor that contains only 1s.\n",
    "# It should have the same size like the numpy array.\n",
    "# Substract it from the previous tensor.\n",
    "tensor = tensor - torch.ones_like(tensor)\n",
    "print(tensor)\n",
    "\n",
    "# Get the 5th element using a index.\n",
    "element = tensor[5]\n",
    "print(element)\n",
    "\n",
    "# Create a tensor that contains only 0s.\n",
    "# It should have the same size like the numpy array.\n",
    "# Multiply it with the previous tensor without any assignment (in place).\n",
    "tensor *= torch.zeros_like(tensor)\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 512, 3])\n",
      "786432\n",
      "torch.Size([1, 786432])\n",
      "torch.Size([786432])\n",
      "torch.Size([512, 512, 3])\n",
      "tensor(91404848.)\n",
      "tensor(116.2273)\n",
      "tensor(255.)\n"
     ]
    }
   ],
   "source": [
    "# Load the image from the last exercise as RGB image.\n",
    "image = skimage.io.imread(\"data/pepo.jpg\")\n",
    "\n",
    "# Convert the image to a tensor\n",
    "image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "# Print its shape\n",
    "print(image.shape) # torch.Size([512, 512, 3])\n",
    "# Flatten the image\n",
    "image = image.view(-1)\n",
    "print(len(image))\n",
    "\n",
    "# Add another dimension resulting in a 1x78643 tensor\n",
    "image = image.unsqueeze(0)\n",
    "print(image.shape)\n",
    "\n",
    "# Revert the last action\n",
    "image = image.squeeze(0)\n",
    "print(image.shape)\n",
    "\n",
    "# Reshape the tensor, so that it has the original 2D dimensions\n",
    "image = image.view(512, 512, 3)\n",
    "print(image.shape)\n",
    "\n",
    "# Calculate the sum, mean and max of the tensor\n",
    "print(torch.sum(image))\n",
    "print(torch.mean(image))\n",
    "print(torch.max(image))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "(2 points)\n",
    "\n",
    "Use Autograd to perform operations on a tensor and output then gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7062, 0.0501],\n",
      "        [0.5140, 0.7364]], requires_grad=True)\n",
      "tensor([[2.7062, 2.0501],\n",
      "        [2.5140, 2.7364]], grad_fn=<AddBackward0>)\n",
      "tensor([[7.3236, 4.2031],\n",
      "        [6.3202, 7.4882]], grad_fn=<PowBackward0>)\n",
      "tensor(6.3338, grad_fn=<MeanBackward0>)\n",
      "tensor([[1.3531, 1.0251],\n",
      "        [1.2570, 1.3682]])\n",
      "False\n",
      "tensor(6.3338)\n"
     ]
    }
   ],
   "source": [
    "# Create a random 2x2 tensor which requires gradients\n",
    "x = torch.rand(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "# Create another tensor by adding 2.0\n",
    "y = x + 2.0\n",
    "print(y)\n",
    "\n",
    "# Create a third tensor z = y^2\n",
    "z = y ** 2\n",
    "print(z)\n",
    "\n",
    "# Compute out as the mean of values in z\n",
    "out = torch.mean(z)\n",
    "print(out)\n",
    "\n",
    "# Perform back propagation on out\n",
    "out.backward()\n",
    "\n",
    "# Print the gradients dout/dx\n",
    "print(x.grad)\n",
    "\n",
    "# Create a copy of y whithout gradients\n",
    "y2 = y.detach()\n",
    "print(y2.requires_grad)\n",
    "\n",
    "# Perform the mean operation on z\n",
    "# with gradients globally disabled\n",
    "with torch.no_grad():\n",
    "    out = torch.mean(z)\n",
    "    print(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "(3 points)\n",
    "\n",
    "Implement a Dataset class for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading mnist.tar.gz\n",
      "Extract mnist.tar.gz\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# We first download the MNIST dataset\n",
    "download_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST:\n",
    "    \"\"\"\n",
    "    Dataset class for MNIST\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, root, transform=None):\n",
    "        \"\"\"\n",
    "        root -- path to either \"training\" or \"testing\"\n",
    "        \n",
    "        transform -- transform (from torchvision.transforms)\n",
    "                     to be applied to the data\n",
    "        \"\"\"\n",
    "        # save transforms\n",
    "        self.transform = transform\n",
    "        \n",
    "        # TODO: create a list of all subdirectories (named like the classes) \n",
    "        #       within the dataset root\n",
    "        \n",
    "        \n",
    "        # TODO: create a list of paths to all images\n",
    "        #       with the ground truth label\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the lenght of the dataset (number of images)\n",
    "        \"\"\"\n",
    "        # TODO: return the length (number of images) of the dataset\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Loads and returns one image as floating point numpy array\n",
    "        \n",
    "        index -- image index in [0, self.__len__() - 1]\n",
    "        \"\"\"\n",
    "        # TODO: load the ith image as an numpy array (dtype=float32)\n",
    "        \n",
    "        \n",
    "        # TODO: apply transforms to the image (if there are any)\n",
    "        \n",
    "        \n",
    "        # TODO: return a tuple (transformed image, ground truth)\n",
    "       "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "(3 points)\n",
    "\n",
    "You can now load a pretrained neural network model we provide.\n",
    "Your last task is to run the model on the MNIST test dataset, plot some example images with the predicted labels and compute the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data_loader):\n",
    "    # TODO: Create a 10x10 grid of subplots\n",
    "   \n",
    "    \n",
    "    model.eval()\n",
    "    correct = 0 # count for correct predictions\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, item in enumerate(data_loader):\n",
    "            # TODO: unpack item into image and ground truth\n",
    "            #       and run network on them\n",
    "            \n",
    "            \n",
    "            # TODO: get class with highest probability\n",
    "            \n",
    "            \n",
    "            # TODO: check if prediction is correct\n",
    "            #       and add it to correct count\n",
    "            \n",
    "            \n",
    "            # plot the first 100 images\n",
    "            if i < 100:\n",
    "                # TODO: compute position of ith image in the grid\n",
    "                \n",
    "                \n",
    "                # TODO: convert image tensor to numpy array\n",
    "                #       and normalize to [0, 1]\n",
    "                \n",
    "                \n",
    "                # TODO: make wrongly predicted images red\n",
    "                \n",
    "                \n",
    "                # TODO: disable axis and show image\n",
    "                \n",
    "                \n",
    "                # TODO: show the predicted class next to each image\n",
    "                \n",
    "            \n",
    "            elif i == 100:\n",
    "                plt.show()\n",
    "    \n",
    "    # TODO: compute and print the prediction accuracy in percent\n",
    "    \n",
    "\n",
    "# create a DataLoader using the implemented MNIST dataset class\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    MNIST('data/mnist/testing',\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])),\n",
    "    batch_size=1, shuffle=True)\n",
    "\n",
    "# create the neural network\n",
    "model = Net()\n",
    "\n",
    "# load the statedict from 'models/mnist/simple_cnn.pt'\n",
    "model.load_state_dict(torch.load('models/mnist/simple_cnn.pt'))\n",
    "\n",
    "# validate the model\n",
    "validate(model, data_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dcv-students",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
